{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict whether a sentence comes from Alice in Wonderland or Persuasion.\n",
    "#Removing the title. Match all text between square brackets and replace with empty string.\n",
    "\n",
    "\n",
    "#Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion) #d+ is to remove the digits behind\n",
    "alice = re.sub(r'CHAPTER .*', '', alice) #* is to remove everything behind.\n",
    "#Without r, you'd have to type each backslash twice in order to pass it to re.sub.\n",
    "#eg r'\\]\\n' is the same as '\\\\'\\]\\n' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "\n",
      "\n",
      "Alice was beginning to get very tired of\n"
     ]
    }
   ],
   "source": [
    "print(alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', '', text)\n",
    "    text = re.sub('[\\[].*?![\\]]', \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the cleaned novels.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([, Alice, 's, Adventures, in, Wonderland, by,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  ([, Alice, 's, Adventures, in, Wonderland, by,...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen'] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Cut Caesar down to the same length as Alice.\n",
    "persuasion_sents = persuasion_sents[0:len(alice_sents)]\n",
    "\n",
    "#Combine the sentences from the two novels into one df.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0        1  sentence_length\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...  Carroll               78\n",
      "1  (So, she, was, considering, in, her, own, mind...  Carroll               63\n",
      "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll               33\n",
      "3                                      (Oh, dear, !)  Carroll                3\n",
      "4                         (I, shall, be, late, !, ')  Carroll                6\n"
     ]
    }
   ],
   "source": [
    "sentences['sentence_length']=sentences[0].str.len()\n",
    "print(sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 1000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "#item 0 is the word, item 1 is the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df with features for each word in our common word set.\n",
    "#Each value is the count of the times the word appears.\n",
    "#BOW is bag of words\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df.loc[:, 'punctuation_length'] = 0\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    #loc you use the column name, iloc you use index (column number)\n",
    "    #: means all rows. columns within common_words would be 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        puncts = [token for token in sentence if (token.is_punct)]\n",
    "        df.loc[i,'punctuation_length'] += len(puncts)\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "#Combine bags to create a set of unique words.\n",
    "#Set takes out duplicates\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twist</th>\n",
       "      <th>week</th>\n",
       "      <th>till</th>\n",
       "      <th>small</th>\n",
       "      <th>differently</th>\n",
       "      <th>warm</th>\n",
       "      <th>strength</th>\n",
       "      <th>persuasion</th>\n",
       "      <th>railway</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>m</th>\n",
       "      <th>rooke</th>\n",
       "      <th>him</th>\n",
       "      <th>folly</th>\n",
       "      <th>purpose</th>\n",
       "      <th>edwin</th>\n",
       "      <th>completely</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>punctuation_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>([, Alice, 's, Adventures, in, Wonderland, by,...</td>\n",
       "      <td>12</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>7</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>4</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>1</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>2</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
       "0      0     0     0      0            0     0         0           0        0   \n",
       "1      0     0     0      0            0     0         0           0        0   \n",
       "2      0     0     0      0            0     0         0           0        0   \n",
       "3      0     0     0      0            0     0         0           0        0   \n",
       "4      0     0     0      0            0     0         0           0        0   \n",
       "\n",
       "   in     ...       m  rooke  him  folly  purpose  edwin  completely  \\\n",
       "0   0     ...       0      0    0      0        0      0           0   \n",
       "1   0     ...       0      0    0      0        0      0           0   \n",
       "2   0     ...       0      0    0      0        0      0           0   \n",
       "3   0     ...       0      0    0      0        0      0           0   \n",
       "4   0     ...       0      0    0      0        0      0           0   \n",
       "\n",
       "                                       text_sentence  punctuation_length  \\\n",
       "0  ([, Alice, 's, Adventures, in, Wonderland, by,...                  12   \n",
       "1  (So, she, was, considering, in, her, own, mind...                   7   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...                   4   \n",
       "3                                      (Oh, dear, !)                   1   \n",
       "4                         (I, shall, be, late, !, ')                   2   \n",
       "\n",
       "   text_source  \n",
       "0      Carroll  \n",
       "1      Carroll  \n",
       "2      Carroll  \n",
       "3      Carroll  \n",
       "4      Carroll  \n",
       "\n",
       "[5 rows x 1566 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the df with features.\n",
    "word_counts = bow_features(sentences,common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the number of words in that sentence into the df.\n",
    "word_counts = pd.concat([word_counts, sentences['sentence_length']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in       ...         rooke  him  folly  purpose  edwin  completely  \\\n",
      "0   0       ...             0    0      0        0      0           0   \n",
      "1   0       ...             0    0      0        0      0           0   \n",
      "2   0       ...             0    0      0        0      0           0   \n",
      "3   0       ...             0    0      0        0      0           0   \n",
      "4   0       ...             0    0      0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...                  12   \n",
      "1  (So, she, was, considering, in, her, own, mind...                   7   \n",
      "2  (There, was, nothing, so, VERY, remarkable, in...                   4   \n",
      "3                                      (Oh, dear, !)                   1   \n",
      "4                         (I, shall, be, late, !, ')                   2   \n",
      "\n",
      "   text_source  sentence_length  \n",
      "0      Carroll               78  \n",
      "1      Carroll               63  \n",
      "2      Carroll               33  \n",
      "3      Carroll                3  \n",
      "4      Carroll                6  \n",
      "\n",
      "[5 rows x 1567 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the previous sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['previous_length'] = word_counts['sentence_length']\n",
    "word_counts['previous_length'] = None\n",
    "\n",
    "#df.shape returns two numbers, for example (10,10). The first number is the row count\n",
    "for i in range(1,word_counts.shape[0]):\n",
    "    word_counts.loc[i,'previous_length'] = word_counts.loc[i-1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set first sentence of Austen to NULL\n",
    "first_sentence = min(word_counts.index[word_counts['text_source'] == 'Austen'].tolist())\n",
    "word_counts.loc[first_sentence, 'previous_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the next sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['next_length'] = word_counts['sentence_length']\n",
    "word_counts['next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,word_counts.shape[-1]):\n",
    "    word_counts.loc[i,'next_length'] = word_counts.loc[i+1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set last sentence of Carroll to NULL\n",
    "last_sentence = max(word_counts.index[word_counts['text_source'] == 'Carroll'].tolist())\n",
    "word_counts.loc[last_sentence, 'next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in     ...       folly  purpose  edwin  completely  \\\n",
      "0   0     ...           0        0      0           0   \n",
      "1   0     ...           0        0      0           0   \n",
      "2   0     ...           0        0      0           0   \n",
      "3   0     ...           0        0      0           0   \n",
      "4   0     ...           0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...                  12   \n",
      "1  (So, she, was, considering, in, her, own, mind...                   7   \n",
      "2  (There, was, nothing, so, VERY, remarkable, in...                   4   \n",
      "3                                      (Oh, dear, !)                   1   \n",
      "4                         (I, shall, be, late, !, ')                   2   \n",
      "\n",
      "   text_source  sentence_length  previous_length  next_length  \n",
      "0      Carroll               78             None           63  \n",
      "1      Carroll               63               78           33  \n",
      "2      Carroll               33               63            3  \n",
      "3      Carroll                3               33            6  \n",
      "4      Carroll                6                3          126  \n",
      "\n",
      "[5 rows x 1569 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_counts['text_sentence'] = word_counts['text_sentence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['previous_length'] = word_counts['previous_length'].fillna(word_counts['previous_length'].mean())\n",
    "word_counts['next_length'] = word_counts['next_length'].fillna(word_counts['next_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in     ...       folly  purpose  edwin  completely  \\\n",
      "0   0     ...           0        0      0           0   \n",
      "1   0     ...           0        0      0           0   \n",
      "2   0     ...           0        0      0           0   \n",
      "3   0     ...           0        0      0           0   \n",
      "4   0     ...           0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...                  12   \n",
      "1  (So, she, was, considering, in, her, own, mind...                   7   \n",
      "2  (There, was, nothing, so, VERY, remarkable, in...                   4   \n",
      "3                                      (Oh, dear, !)                   1   \n",
      "4                         (I, shall, be, late, !, ')                   2   \n",
      "\n",
      "   text_source  sentence_length  previous_length  next_length  \n",
      "0      Carroll               78        25.501813         63.0  \n",
      "1      Carroll               63        78.000000         33.0  \n",
      "2      Carroll               33        63.000000          3.0  \n",
      "3      Carroll                3        33.000000          6.0  \n",
      "4      Carroll                6         3.000000        126.0  \n",
      "\n",
      "[5 rows x 1569 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.997986914947\n",
      "\n",
      "Test set score 0.96679245283\n"
     ]
    }
   ],
   "source": [
    "#Trying random forest\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'],1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97289157,  0.9652568 ,  0.97280967,  0.98338369,  0.90936556])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overfitting is usually a problem when using bag of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1987, 1567) (1987,)\n",
      "Training set score 0.968797181681\n",
      "\n",
      "Test set score 0.896603773585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score', lr.score(X_train, y_train))\n",
    "print('\\nTest set score', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86746988,  0.86253776,  0.8836858 ,  0.89879154,  0.88217523])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.989934574736\n",
      "\n",
      "Test set score 0.979622641509\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "print('Training set score', clf.score(X_train, y_train))\n",
    "print('\\nTest set score', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9939759 ,  1.        ,  1.        ,  1.        ,  0.86858006])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.980372420735\n",
      "\n",
      "Test set score 0.887547169811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = svm.SVC()\n",
    "parameters = {'kernel':('linear', 'rbf')}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "\n",
    "train = clf.fit(X_train,y_train)\n",
    "print('Training set score', clf.score(X_train, y_train))\n",
    "print('\\nTest set score', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85090361,  0.84441088,  0.85951662,  0.88821752,  0.8776435 ])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier achieved the best results for this model. Test score was 9.979! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine if the model is able to process Austen's Emma (instead of Persuasion) from Carroll with the \n",
    "#same amount of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816] Emma Woodhouse, handsome, clever, and rich, with a comfortable home and h\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group into sentences\n",
    "persuasion_sents = [[sent, 'Austen'] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, 'Austen'] for sent in emma_doc.sents]\n",
    "\n",
    "#Cut down Emma to the same length as Alice.\n",
    "emma_sents = emma_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Build BOW df for Emma word counts. Use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_sentences['sentence_length'] = emma_sentences[0].str.len()\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma_bow['sentence_length'] = emma_sentences[0].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in       ...         rooke  him  folly  purpose  edwin  completely  \\\n",
      "0   0       ...             0    0      0        0      0           0   \n",
      "1   0       ...             0    0      0        0      0           0   \n",
      "2   0       ...             0    0      0        0      0           0   \n",
      "3   0       ...             0    0      0        0      0           0   \n",
      "4   0       ...             0    0      0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Emma, by, Jane, Austen, 1816, ], Emma, Woo...                  10   \n",
      "1  (She, was, the, youngest, of, the, two, daught...                   5   \n",
      "2  (Her, mother, had, died, too, long, ago, for, ...                   3   \n",
      "3  (Sixteen, years, had, Miss, Taylor, been, in, ...                   4   \n",
      "4                                 (Between, _, them)                   1   \n",
      "\n",
      "   text_source  sentence_length  \n",
      "0       Austen               56  \n",
      "1       Austen               38  \n",
      "2       Austen               44  \n",
      "3       Austen               31  \n",
      "4       Austen                3  \n",
      "\n",
      "[5 rows x 1567 columns]\n"
     ]
    }
   ],
   "source": [
    "print(emma_bow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the previous sentence.\n",
    "#Create new column. Set to NULL\n",
    "emma_bow['previous_length'] = emma_bow['sentence_length']\n",
    "emma_bow['previous_length'] = None\n",
    "\n",
    "#df.shape returns two numbers, for example (10,10). The first number is the row count\n",
    "for i in range(1,emma_bow.shape[0]):\n",
    "    emma_bow.loc[i,'previous_length'] = emma_bow.loc[i-1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in       ...         him  folly  purpose  edwin  completely  \\\n",
      "0   0       ...           0      0        0      0           0   \n",
      "1   0       ...           0      0        0      0           0   \n",
      "2   0       ...           0      0        0      0           0   \n",
      "3   0       ...           0      0        0      0           0   \n",
      "4   0       ...           0      0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Emma, by, Jane, Austen, 1816, ], Emma, Woo...                  10   \n",
      "1  (She, was, the, youngest, of, the, two, daught...                   5   \n",
      "2  (Her, mother, had, died, too, long, ago, for, ...                   3   \n",
      "3  (Sixteen, years, had, Miss, Taylor, been, in, ...                   4   \n",
      "4                                 (Between, _, them)                   1   \n",
      "\n",
      "   text_source  sentence_length  previous_length  \n",
      "0       Austen               56             None  \n",
      "1       Austen               38               56  \n",
      "2       Austen               44               38  \n",
      "3       Austen               31               44  \n",
      "4       Austen                3               31  \n",
      "\n",
      "[5 rows x 1568 columns]\n"
     ]
    }
   ],
   "source": [
    "print(emma_bow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set first sentence of Austen to NULL\n",
    "#first_sentence = min(emma_bow.index[word_counts['text_source'] == 'Austen'].tolist())\n",
    "#emma_bow.loc[first_sentence, 'previous_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the next sentence.\n",
    "#Create new column. Set to NULL\n",
    "emma_bow['next_length'] = emma_bow['sentence_length']\n",
    "#emma_bow['next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,emma_bow.shape[-1]):\n",
    "    emma_bow.loc[i,'next_length'] = emma_bow.loc[i+1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set last sentence of Austen to NULL\n",
    "#last_sentence = max(emma_bow.index[emma_bow['text_source'] == 'Austen'].tolist())\n",
    "#emma_bow.loc[last_sentence, 'next_length'] = None\n",
    "\n",
    "emma_bow['previous_length'] = emma_bow['previous_length'].fillna(emma_bow['previous_length'].mean())\n",
    "#emma_bow['next_length'] = emma_bow['next_length'].fillna(emma_bow['next_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   twist  week  till  small  differently  warm  strength  persuasion  railway  \\\n",
      "0      0     0     0      0            0     0         0           0        0   \n",
      "1      0     0     0      0            0     0         0           0        0   \n",
      "2      0     0     0      0            0     0         0           0        0   \n",
      "3      0     0     0      0            0     0         0           0        0   \n",
      "4      0     0     0      0            0     0         0           0        0   \n",
      "\n",
      "   in     ...       folly  purpose  edwin  completely  \\\n",
      "0   0     ...           0        0      0           0   \n",
      "1   0     ...           0        0      0           0   \n",
      "2   0     ...           0        0      0           0   \n",
      "3   0     ...           0        0      0           0   \n",
      "4   0     ...           0        0      0           0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Emma, by, Jane, Austen, 1816, ], Emma, Woo...                  10   \n",
      "1  (She, was, the, youngest, of, the, two, daught...                   5   \n",
      "2  (Her, mother, had, died, too, long, ago, for, ...                   3   \n",
      "3  (Sixteen, years, had, Miss, Taylor, been, in, ...                   4   \n",
      "4                                 (Between, _, them)                   1   \n",
      "\n",
      "   text_source  sentence_length  previous_length  next_length  \n",
      "0       Austen               56        22.145619           38  \n",
      "1       Austen               38        56.000000           44  \n",
      "2       Austen               44        38.000000           31  \n",
      "3       Austen               31        44.000000            3  \n",
      "4       Austen                3        31.000000            1  \n",
      "\n",
      "[5 rows x 1569 columns]\n"
     ]
    }
   ],
   "source": [
    "print(emma_bow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.685213414634\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1329</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>499</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1329      327\n",
       "Carroll     499      469"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using logistic regression to model.\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
