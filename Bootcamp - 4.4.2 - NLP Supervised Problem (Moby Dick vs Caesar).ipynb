{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "moby = gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = re.sub(r'Actus .*', '', caesar)\n",
    "\n",
    "#Remove newlines and other white spaces by splitting and rejoining\n",
    "caesar = ' '.join(caesar.split())\n",
    "moby = ' '.join(moby.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Julius Caesar by William Shakespeare 1599] Enter Flauius, Murellus, and certaine Commoners ouer the Stage. Flauius. Hence: home you idle Creatures, get you home: Is this a Holiday? What, know you not (Being Mechanicall) you ought not walke Vpon a labouring day, without the signe Of your Profession? Speake, what Trade art thou? Car. Why Sir, a Carpenter Mur. Where is thy Leather Ap\n",
      "[Moby Dick by Herman Melville 1851] ETYMOLOGY. (Supplied by a Late Consumptive Usher to a Grammar School) The pale Usher--threadbare in coat, heart, body, and brain; I see him now. He was ever dusting his old lexicons and grammars, with a queer handkerchief, mockingly embellished with all the gay flags of all the known nations of the world. He loved to dust his old grammars; it somehow mildly remi\n"
     ]
    }
   ],
   "source": [
    "print(caesar[0:400])\n",
    "print(moby[0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the cleaned novels.\n",
    "nlp = spacy.load('en')\n",
    "moby_doc = nlp(moby)\n",
    "caesar_doc = nlp(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', '', text)\n",
    "    text = re.sub('[\\[]:.*?[\\]]()', \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "moby = text_cleaner(moby)\n",
    "caesar = text_cleaner(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([, Moby, Dick, by, Herman, Melville, 1851, ],...</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(The, pale, Usher, --, threadbare, in, coat, ,...</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(He, was, ever, dusting, his, old, lexicons, a...</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0         1\n",
       "0  ([, Moby, Dick, by, Herman, Melville, 1851, ],...  Merville\n",
       "1            ((, Supplied, by, a, Late, Consumptive)  Merville\n",
       "2                 (Usher, to, a, Grammar, School, ))  Merville\n",
       "3  (The, pale, Usher, --, threadbare, in, coat, ,...  Merville\n",
       "4  (He, was, ever, dusting, his, old, lexicons, a...  Merville"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "moby_sents = [[sent, \"Merville\"] for sent in moby_doc.sents]\n",
    "caesar_sents = [[sent, 'Shakespeare'] for sent in caesar_doc.sents]\n",
    "\n",
    "# Cut Caesar down to the same length as Moby.\n",
    "caesar_sents = caesar_sents[0:len(moby_sents)]\n",
    "\n",
    "#Combine the sentences from the two novels into one df.\n",
    "sentences = pd.DataFrame(moby_sents + caesar_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0         1  \\\n",
      "0  ([, Moby, Dick, by, Herman, Melville, 1851, ],...  Merville   \n",
      "1            ((, Supplied, by, a, Late, Consumptive)  Merville   \n",
      "2                 (Usher, to, a, Grammar, School, ))  Merville   \n",
      "3  (The, pale, Usher, --, threadbare, in, coat, ,...  Merville   \n",
      "4  (He, was, ever, dusting, his, old, lexicons, a...  Merville   \n",
      "\n",
      "   sentence_length  \n",
      "0               10  \n",
      "1                6  \n",
      "2                6  \n",
      "3               20  \n",
      "4               31  \n"
     ]
    }
   ],
   "source": [
    "#Code that counts length row by row, i.e. sentence by sentence\n",
    "sentences['sentence_length']=sentences[0].str.len()\n",
    "print(sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 1000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df with features for each word in our common word set.\n",
    "#Each value is the count of the times the word appears.\n",
    "#BOW is bag of words\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df.loc[:, 'punctuation_length'] = 0\n",
    "    #df.loc[:, 'unique_words'] = 0\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    #loc you use the column name, iloc you use index (column number)\n",
    "    #: means all rows. columns within common_words would be 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        puncts = [token for token in sentence if (token.is_punct)]\n",
    "        df.loc[i,'punctuation_length'] += len(puncts)\n",
    "        \n",
    "        #example_words = [token for token in example_sentence if not token.is_punct]\n",
    "        #unique_words = set([token.text for token in example_words])\n",
    "        #df.loc[i, 'unique_words'] += len(unique_words)\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the bags.\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "caesarwords = bag_of_words(caesar_doc)\n",
    "\n",
    "#Combine bags to create a set of unique words.\n",
    "#Set takes out duplicates\n",
    "common_words = set(mobywords + caesarwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Processing row 9000\n",
      "Processing row 9500\n",
      "Processing row 10000\n",
      "Processing row 10500\n",
      "Processing row 11000\n",
      "Processing row 11500\n",
      "Processing row 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blow</th>\n",
       "      <th>bit</th>\n",
       "      <th>ride</th>\n",
       "      <th>swift</th>\n",
       "      <th>be</th>\n",
       "      <th>flee</th>\n",
       "      <th>hammock</th>\n",
       "      <th>cymber</th>\n",
       "      <th>wake</th>\n",
       "      <th>what</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>answer'd</th>\n",
       "      <th>lucil</th>\n",
       "      <th>finde</th>\n",
       "      <th>passe</th>\n",
       "      <th>swell</th>\n",
       "      <th>sirra</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>punctuation_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>([, Moby, Dick, by, Herman, Melville, 1851, ],...</td>\n",
       "      <td>3</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>((, Supplied, by, a, Late, Consumptive)</td>\n",
       "      <td>1</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Usher, to, a, Grammar, School, ))</td>\n",
       "      <td>1</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, pale, Usher, --, threadbare, in, coat, ,...</td>\n",
       "      <td>6</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(He, was, ever, dusting, his, old, lexicons, a...</td>\n",
       "      <td>3</td>\n",
       "      <td>Merville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1694 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   blow  bit  ride  swift  be  flee  hammock  cymber  wake  what     ...       \\\n",
       "0     0    0     0      0   0     0        0       0     0     0     ...        \n",
       "1     0    0     0      0   0     0        0       0     0     0     ...        \n",
       "2     0    0     0      0   0     0        0       0     0     0     ...        \n",
       "3     0    0     0      0   0     0        0       0     0     0     ...        \n",
       "4     0    0     0      0   0     0        0       0     0     0     ...        \n",
       "\n",
       "   year  answer'd  lucil  finde  passe  swell  sirra  \\\n",
       "0     0         0      0      0      0      0      0   \n",
       "1     0         0      0      0      0      0      0   \n",
       "2     0         0      0      0      0      0      0   \n",
       "3     0         0      0      0      0      0      0   \n",
       "4     0         0      0      0      0      0      0   \n",
       "\n",
       "                                       text_sentence  punctuation_length  \\\n",
       "0  ([, Moby, Dick, by, Herman, Melville, 1851, ],...                   3   \n",
       "1            ((, Supplied, by, a, Late, Consumptive)                   1   \n",
       "2                 (Usher, to, a, Grammar, School, ))                   1   \n",
       "3  (The, pale, Usher, --, threadbare, in, coat, ,...                   6   \n",
       "4  (He, was, ever, dusting, his, old, lexicons, a...                   3   \n",
       "\n",
       "   text_source  \n",
       "0     Merville  \n",
       "1     Merville  \n",
       "2     Merville  \n",
       "3     Merville  \n",
       "4     Merville  \n",
       "\n",
       "[5 rows x 1694 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the df with features.\n",
    "word_counts = bow_features(sentences,common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the number of words in that sentence into the df.\n",
    "word_counts = pd.concat([word_counts, sentences['sentence_length']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the previous sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['previous_length'] = word_counts['sentence_length']\n",
    "word_counts['previous_length'] = None\n",
    "\n",
    "#df.shape returns two numbers, for example (10,10). The first number is the row count\n",
    "for i in range(1,word_counts.shape[0]):\n",
    "    word_counts.loc[i,'previous_length'] = word_counts.loc[i-1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set first sentence of Merville to NULL\n",
    "first_sentence = min(word_counts.index[word_counts['text_source'] == 'Merville'].tolist())\n",
    "word_counts.loc[first_sentence, 'previous_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the next sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['next_length'] = word_counts['sentence_length']\n",
    "word_counts['next_length'] = None\n",
    "\n",
    "for i in range(0,word_counts.shape[-1]):\n",
    "    word_counts.loc[i,'next_length'] = word_counts.loc[i+1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set last sentence of Carroll to NULL\n",
    "last_sentence = max(word_counts.index[word_counts['text_source'] == 'Shakespeare'].tolist())\n",
    "word_counts.loc[last_sentence, 'next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['previous_length'] = word_counts['previous_length'].fillna(word_counts['previous_length'].mean())\n",
    "word_counts['next_length'] = word_counts['next_length'].fillna(word_counts['next_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   blow  bit  ride  swift  be  flee  hammock  cymber  wake  what     ...       \\\n",
      "0     0    0     0      0   0     0        0       0     0     0     ...        \n",
      "1     0    0     0      0   0     0        0       0     0     0     ...        \n",
      "2     0    0     0      0   0     0        0       0     0     0     ...        \n",
      "3     0    0     0      0   0     0        0       0     0     0     ...        \n",
      "4     0    0     0      0   0     0        0       0     0     0     ...        \n",
      "\n",
      "   finde  passe  swell  sirra  \\\n",
      "0      0      0      0      0   \n",
      "1      0      0      0      0   \n",
      "2      0      0      0      0   \n",
      "3      0      0      0      0   \n",
      "4      0      0      0      0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Moby, Dick, by, Herman, Melville, 1851, ],...                   3   \n",
      "1            ((, Supplied, by, a, Late, Consumptive)                   1   \n",
      "2                 (Usher, to, a, Grammar, School, ))                   1   \n",
      "3  (The, pale, Usher, --, threadbare, in, coat, ,...                   6   \n",
      "4  (He, was, ever, dusting, his, old, lexicons, a...                   3   \n",
      "\n",
      "   text_source  sentence_length  previous_length  next_length  \n",
      "0     Merville               10        23.119427          6.0  \n",
      "1     Merville                6        10.000000          6.0  \n",
      "2     Merville                6         6.000000         20.0  \n",
      "3     Merville               20         6.000000         31.0  \n",
      "4     Merville               31        20.000000         18.0  \n",
      "\n",
      "[5 rows x 1697 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.99186440678\n",
      "\n",
      "Test set score 0.930662871086\n"
     ]
    }
   ],
   "source": [
    "#Trying random forest\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'],1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91459943  0.90890606  0.9402196   0.92717657  0.9182262 ]\n",
      "\n",
      "Mean cross validation score is: 0.921825571595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rfc_score = cross_val_score(rfc, X, Y, cv=5)\n",
    "print(rfc_score)\n",
    "print ('\\nMean cross validation score is: ' + str(np.mean(rfc_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.915661016949\n",
      "\n",
      "Test set score 0.909109394063\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "print('Training set score', clf.score(X_train, y_train))\n",
    "print('\\nTest set score', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88735258  0.89914599  0.91581944  0.90195281  0.89747762]\n",
      "\n",
      "Mean cross validation score is: 0.90034968934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "gb_score = cross_val_score(clf, X, Y, cv=5)\n",
    "print(gb_score)\n",
    "print ('\\nMean cross validation score is: ' + str(np.mean(gb_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model did not work as well for Moby Dick against Julius Caesar. Random Forest shows signs of overfitting. \n",
    "#Potentially more features could be added, such as number of unique words in each sentence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
