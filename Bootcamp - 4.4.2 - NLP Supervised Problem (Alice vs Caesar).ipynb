{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict whether a sentence comes from Alice in Wonderland or Caesar.\n",
    "#Removing the title. Match all text between square brackets and replace with empty string.\n",
    "\n",
    "#Load and clean the data.\n",
    "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = re.sub(r'Actus .*', '', caesar)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "\n",
    "#Remove newlines and other white spaces by splitting and rejoining\n",
    "caesar = ' '.join(caesar.split())\n",
    "alice = ' '.join(alice.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865] Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?' So she was considering in her own mind (a\n",
      "[The Tragedie of Julius Caesar by William Shakespeare 1599] Enter Flauius, Murellus, and certaine Commoners ouer the Stage. Flauius. Hence: home you idle Creatures, get you home: Is this a Holiday? What, know you not (Being Mechanicall) you ought not walke Vpon a labouring day, without the signe Of your Profession? Speake, what Trade art thou? Car. Why Sir, a Carpenter Mur. Where is thy Leather Ap\n"
     ]
    }
   ],
   "source": [
    "print(alice[0:400])\n",
    "print(caesar[0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the cleaned novels.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "caesar_doc = nlp(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', '', text)\n",
    "    text = re.sub('[\\[]:.*?[\\]]()', \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "caesar = text_cleaner(caesar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([, Alice, 's, Adventures, in, Wonderland, by,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  ([, Alice, 's, Adventures, in, Wonderland, by,...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "caesar_sents = [[sent, 'Shakespeare'] for sent in caesar_doc.sents]\n",
    "\n",
    "# Cut Caesar down to the same length as Alice.\n",
    "caesar_sents = caesar_sents[0:len(alice_sents)]\n",
    "\n",
    "#Combine the sentences from the two novels into one df.\n",
    "sentences = pd.DataFrame(alice_sents + caesar_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0        1  sentence_length\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...  Carroll               78\n",
      "1  (So, she, was, considering, in, her, own, mind...  Carroll               63\n",
      "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll               33\n",
      "3                                      (Oh, dear, !)  Carroll                3\n",
      "4                         (I, shall, be, late, !, ')  Carroll                6\n"
     ]
    }
   ],
   "source": [
    "#previous line that counts for whole column\n",
    "#sentences['sentence_length']= len(sentences)\n",
    "\n",
    "#correct code line that counts length row by row, i.e. sentence by sentence\n",
    "sentences['sentence_length']=sentences[0].str.len()\n",
    "print(sentences.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 1000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df with features for each word in our common word set.\n",
    "#Each value is the count of the times the word appears.\n",
    "#BOW is bag of words\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df.loc[:, 'punctuation_length'] = 0\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    #loc you use the column name, iloc you use index (column number)\n",
    "    #: means all rows. columns within common_words would be 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        puncts = [token for token in sentence if (token.is_punct)]\n",
    "        df.loc[i,'punctuation_length'] += len(puncts)\n",
    "        \n",
    "        example\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = [token for token in example_sentence if not token.is_punct]\n",
    "unique_words = set([token.text for token in example_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Identify words according to which POS they belong to. \n",
    "def distinct_words_of_pos(text, pos):\n",
    "    sent_word_tokens = [nltk.word_tokenize(s) for s in nltk.sent_tokenize(text)]\n",
    "    all_pos = nltk.pos_tag_sents(sent_word_tokens, tagset=\"universal\")\n",
    " \n",
    "    uniques = { x[0].lower() for el in all_pos for x in el if x[1]==pos }\n",
    "    return sorted(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "caesarwords = bag_of_words(caesar_doc)\n",
    "\n",
    "#Combine bags to create a set of unique words.\n",
    "#Set takes out duplicates\n",
    "common_words = set(alicewords + caesarwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sorrowful</th>\n",
       "      <th>cynna</th>\n",
       "      <th>destruction</th>\n",
       "      <th>ambition</th>\n",
       "      <th>dardanius</th>\n",
       "      <th>knowne</th>\n",
       "      <th>spurne</th>\n",
       "      <th>plebeians</th>\n",
       "      <th>sicknesse</th>\n",
       "      <th>preuent</th>\n",
       "      <th>...</th>\n",
       "      <th>slay</th>\n",
       "      <th>barren</th>\n",
       "      <th>plenty</th>\n",
       "      <th>gate</th>\n",
       "      <th>rabbit</th>\n",
       "      <th>edge</th>\n",
       "      <th>examine</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>punctuation_length</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>([, Alice, 's, Adventures, in, Wonderland, by,...</td>\n",
       "      <td>12</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>7</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>4</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>1</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>2</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sorrowful  cynna  destruction  ambition  dardanius  knowne  spurne  \\\n",
       "0          0      0            0         0          0       0       0   \n",
       "1          0      0            0         0          0       0       0   \n",
       "2          0      0            0         0          0       0       0   \n",
       "3          0      0            0         0          0       0       0   \n",
       "4          0      0            0         0          0       0       0   \n",
       "\n",
       "   plebeians  sicknesse  preuent     ...       slay  barren  plenty  gate  \\\n",
       "0          0          0        0     ...          0       0       0     0   \n",
       "1          0          0        0     ...          0       0       0     0   \n",
       "2          0          0        0     ...          0       0       0     0   \n",
       "3          0          0        0     ...          0       0       0     0   \n",
       "4          0          0        0     ...          0       0       0     0   \n",
       "\n",
       "   rabbit  edge  examine                                      text_sentence  \\\n",
       "0       0     0        0  ([, Alice, 's, Adventures, in, Wonderland, by,...   \n",
       "1       1     0        0  (So, she, was, considering, in, her, own, mind...   \n",
       "2       1     0        0  (There, was, nothing, so, VERY, remarkable, in...   \n",
       "3       0     0        0                                      (Oh, dear, !)   \n",
       "4       0     0        0                         (I, shall, be, late, !, ')   \n",
       "\n",
       "   punctuation_length  text_source  \n",
       "0                  12      Carroll  \n",
       "1                   7      Carroll  \n",
       "2                   4      Carroll  \n",
       "3                   1      Carroll  \n",
       "4                   2      Carroll  \n",
       "\n",
       "[5 rows x 1737 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the df with features.\n",
    "word_counts = bow_features(sentences,common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat the number of words in that sentence into the df.\n",
    "word_counts = pd.concat([word_counts, sentences['sentence_length']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the previous sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['previous_length'] = word_counts['sentence_length']\n",
    "word_counts['previous_length'] = None\n",
    "\n",
    "#df.shape returns two numbers, for example (10,10). The first number is the row count\n",
    "for i in range(1,word_counts.shape[0]):\n",
    "    word_counts.loc[i,'previous_length'] = word_counts.loc[i-1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set first sentence of Shakespeare to NULL\n",
    "first_sentence = min(word_counts.index[word_counts['text_source'] == 'Shakespeare'].tolist())\n",
    "word_counts.loc[first_sentence, 'previous_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include column with number of words in the next sentence.\n",
    "#Create new column. Set to NULL\n",
    "word_counts['next_length'] = word_counts['sentence_length']\n",
    "word_counts['next_length'] = None\n",
    "\n",
    "for i in range(0,word_counts.shape[-1]):\n",
    "    word_counts.loc[i,'next_length'] = word_counts.loc[i+1,'sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set last sentence of Carroll to NULL\n",
    "last_sentence = max(word_counts.index[word_counts['text_source'] == 'Carroll'].tolist())\n",
    "word_counts.loc[last_sentence, 'next_length'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['previous_length'] = word_counts['previous_length'].fillna(word_counts['previous_length'].mean())\n",
    "word_counts['next_length'] = word_counts['next_length'].fillna(word_counts['next_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sorrowful  cynna  destruction  ambition  dardanius  knowne  spurne  \\\n",
      "0          0      0            0         0          0       0       0   \n",
      "1          0      0            0         0          0       0       0   \n",
      "2          0      0            0         0          0       0       0   \n",
      "3          0      0            0         0          0       0       0   \n",
      "4          0      0            0         0          0       0       0   \n",
      "\n",
      "   plebeians  sicknesse  preuent     ...       gate  rabbit  edge  examine  \\\n",
      "0          0          0        0     ...          0       0     0        0   \n",
      "1          0          0        0     ...          0       1     0        0   \n",
      "2          0          0        0     ...          0       1     0        0   \n",
      "3          0          0        0     ...          0       0     0        0   \n",
      "4          0          0        0     ...          0       0     0        0   \n",
      "\n",
      "                                       text_sentence  punctuation_length  \\\n",
      "0  ([, Alice, 's, Adventures, in, Wonderland, by,...                  12   \n",
      "1  (So, she, was, considering, in, her, own, mind...                   7   \n",
      "2  (There, was, nothing, so, VERY, remarkable, in...                   4   \n",
      "3                                      (Oh, dear, !)                   1   \n",
      "4                         (I, shall, be, late, !, ')                   2   \n",
      "\n",
      "   text_source  sentence_length  previous_length  next_length  \n",
      "0      Carroll               78        16.293977         63.0  \n",
      "1      Carroll               63        78.000000         33.0  \n",
      "2      Carroll               33        63.000000          3.0  \n",
      "3      Carroll                3        33.000000          6.0  \n",
      "4      Carroll                6         3.000000        126.0  \n",
      "\n",
      "[5 rows x 1740 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example_words = [token for token in example_sentence if not token.is_punct]\n",
    "unique_words = set([token.text for token in example_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.998509687034\n",
      "\n",
      "Test set score 0.970215934475\n"
     ]
    }
   ],
   "source": [
    "#Trying random forest\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'],1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90922619  0.99702381  0.98511905  0.99104478  0.98059701]\n",
      "\n",
      "Mean cross validation score is: 0.972602167733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rfc_score = cross_val_score(rfc, X, Y, cv=5)\n",
    "print(rfc_score)\n",
    "print ('\\nMean cross validation score is: ' + str(np.mean(rfc_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score 0.99652260308\n",
      "\n",
      "Test set score 0.98808637379\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "print('Training set score', clf.score(X_train, y_train))\n",
    "print('\\nTest set score', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9077381   0.99702381  1.          1.          0.99701493]\n",
      "\n",
      "Mean cross validation score is: 0.980355366027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "gb_score = cross_val_score(clf, X, Y, cv=5)\n",
    "print(gb_score)\n",
    "print ('\\nMean cross validation score is: ' + str(np.mean(gb_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
